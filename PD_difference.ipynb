{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\farha\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import multiprocessing as mp\n",
    "\n",
    "# data wrangling libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# NEM data libraries\n",
    "# NEMOSIS for actual demand data\n",
    "# NEMSEER for forecast demand data\n",
    "import nemosis\n",
    "from nemseer import compile_data, download_raw_data, generate_runtimes\n",
    "\n",
    "# interactive plotting\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "# progress bar for error computation\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis start and end times\n",
    "analysis_start = \"2021/01/01 00:30:00\"\n",
    "analysis_end = \"2022/01/01 00:00:00\"\n",
    "times = pd.date_range(analysis_start, analysis_end, freq=\"30T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching data for table TRADINGPRICE\n",
      "Cache for TRADINGPRICE in date range already compiled in nemosis_cache.\n",
      "Cache for TRADINGPRICE in date range already compiled in nemosis_cache.\n",
      "Cache for TRADINGPRICE in date range already compiled in nemosis_cache.\n",
      "Cache for TRADINGPRICE in date range already compiled in nemosis_cache.\n",
      "Cache for TRADINGPRICE in date range already compiled in nemosis_cache.\n",
      "Cache for TRADINGPRICE in date range already compiled in nemosis_cache.\n",
      "Cache for TRADINGPRICE in date range already compiled in nemosis_cache.\n",
      "Cache for TRADINGPRICE in date range already compiled in nemosis_cache.\n",
      "Cache for TRADINGPRICE in date range already compiled in nemosis_cache.\n",
      "Cache for TRADINGPRICE in date range already compiled in nemosis_cache.\n",
      "Cache for TRADINGPRICE in date range already compiled in nemosis_cache.\n",
      "Cache for TRADINGPRICE in date range already compiled in nemosis_cache.\n",
      "Cache for TRADINGPRICE in date range already compiled in nemosis_cache.\n"
     ]
    }
   ],
   "source": [
    "# create nemosis cache path and compile cache\n",
    "nemosis_cache = Path(\"nemosis_cache/\")\n",
    "if not nemosis_cache.exists():\n",
    "    nemosis_cache.mkdir()\n",
    "    \n",
    "nemosis.cache_compiler(\n",
    "    analysis_start, analysis_end, \"TRADINGPRICE\", nemosis_cache, fformat=\"parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Query raw data already downloaded to nemseer_cache\n"
     ]
    }
   ],
   "source": [
    "# download raw data from NEMWEB\n",
    "download_raw_data(\n",
    "    \"PREDISPATCH\",\n",
    "    \"PRICE\",\n",
    "    \"nemseer_cache/\",\n",
    "    forecasted_start=analysis_start,\n",
    "    forecasted_end=analysis_end,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate predispatch price forecast error for single time period \n",
    "def calculate_pd_price_forecast_error(forecasted_time: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculates P5MIN demand forecast error (Actual - Forecast) for all forecasts\n",
    "    that are run for a given forecasted_time.\n",
    "\n",
    "    Args:\n",
    "        forecasted_time: Datetime string in the form YYYY/mm/dd HH:MM:SS\n",
    "    Returns:\n",
    "        pandas DataFrame with forecast error in `TOTALDEMAND` columns, the ahead time\n",
    "        of the forecast run in `ahead_time`, and the forecasted time in\n",
    "        `forecasted_time`.\n",
    "    \"\"\"\n",
    "    # necessary for datetime indexing with pandas and xarray\n",
    "    time = str(forecasted_time).replace(\"-\", \"/\")\n",
    "    \n",
    "    # get forecast data for forecasted_time\n",
    "    run_start, run_end = generate_runtimes(time, time, \"PREDISPATCH\")\n",
    "    nemseer_data = compile_data(\n",
    "        run_start,\n",
    "        run_end,\n",
    "        time,\n",
    "        time,\n",
    "        \"PREDISPATCH\",\n",
    "        \"PRICE\",\n",
    "        \"nemseer_cache/\",\n",
    "        data_format=\"xr\",\n",
    "    )\n",
    "    price_forecasts = nemseer_data[\"PRICE\"]\n",
    "    price_forecasts= price_forecasts.where(price_forecasts.INTERVENTION == 0) \n",
    "    \n",
    "    # get actual demand data for forecasted_time\n",
    "    # nemosis start time must precede end of interval of interest by 5 minutes\n",
    "    nemosis_start = (\n",
    "        datetime.strptime(time, \"%Y/%m/%d %H:%M:%S\") - timedelta(minutes=30)\n",
    "    ).strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "    # compile data using nemosis, using cached parquet and filtering out interventions\n",
    "    # select appropriate region\n",
    "    nemosis_data = nemosis.dynamic_data_compiler(\n",
    "        nemosis_start,\n",
    "        time,\n",
    "        \"TRADINGPRICE\",\n",
    "        nemosis_cache,\n",
    "        filter_cols=[\"REGIONID\"],\n",
    "        filter_values=([\"SA1\"],),\n",
    "        fformat=\"parquet\",\n",
    "    )\n",
    "    \n",
    "    # select relevant price index from:\n",
    "    # RRP, RAISE6SECRRP, RAISE60SECRRP, RAISE5MINRRP , RAISEREGRRP\n",
    "    #      LOWER6SECRRP, LOWER60SECRRP, LOWER5MINRRP , LOWERREGRRP \n",
    "    actual_price = nemosis_data.groupby(\"SETTLEMENTDATE\")[\"RRP\"].sum()[time]\n",
    "    \n",
    "    # sum forecast price for relevant region: QLD1 SA1 NSW1 VIC1 TAS1\n",
    "    price_forecasts=price_forecasts.sel(REGIONID=\"QLD1\")\n",
    "    query_forecasts = price_forecasts.sel(forecasted_time=time)[\"RRP\"]\n",
    "    \n",
    "    # calculate error and return as a pandas DataFrame\n",
    "    error = (actual_price - query_forecasts).to_dataframe()\n",
    "    # calculate number of minutes ahead\n",
    "    error[\"ahead_time\"] = error[\"forecasted_time\"] - error.index\n",
    "    error = error.set_index(\"forecasted_time\")\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = pd.date_range(analysis_start, analysis_end, freq=\"30T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = map(calculate_pd_price_forecast_error, times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Query raw data already downloaded to nemseer_cache\n",
      "INFO: Converting PRICE data to xarray.\n",
      "Compiling data for table TRADINGPRICE.\n",
      "Returning TRADINGPRICE.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "datetime64 type does not support add operations",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36mcalculate_pd_price_forecast_error\u001b[1;34m(forecasted_time)\u001b[0m\n\u001b[0;32m     39\u001b[0m nemosis_data \u001b[38;5;241m=\u001b[39m nemosis\u001b[38;5;241m.\u001b[39mdynamic_data_compiler(\n\u001b[0;32m     40\u001b[0m     nemosis_start,\n\u001b[0;32m     41\u001b[0m     time,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     46\u001b[0m     fformat\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparquet\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     47\u001b[0m )\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# select relevant price index from:\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# RRP, RAISE6SECRRP, RAISE60SECRRP, RAISE5MINRRP , RAISEREGRRP\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m#      LOWER6SECRRP, LOWER60SECRRP, LOWER5MINRRP , LOWERREGRRP \u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m actual_price \u001b[38;5;241m=\u001b[39m \u001b[43mnemosis_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSETTLEMENTDATE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRRP\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[time]\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# sum forecast price for relevant region: QLD1 SA1 NSW1 VIC1 TAS1\u001b[39;00m\n\u001b[0;32m     55\u001b[0m price_forecasts\u001b[38;5;241m=\u001b[39mprice_forecasts\u001b[38;5;241m.\u001b[39msel(REGIONID\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQLD1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2189\u001b[0m, in \u001b[0;36mGroupBy.sum\u001b[1;34m(self, numeric_only, min_count, engine, engine_kwargs)\u001b[0m\n\u001b[0;32m   2185\u001b[0m \u001b[38;5;66;03m# If we are grouping on categoricals we want unobserved categories to\u001b[39;00m\n\u001b[0;32m   2186\u001b[0m \u001b[38;5;66;03m# return zero, rather than the default of NaN which the reindexing in\u001b[39;00m\n\u001b[0;32m   2187\u001b[0m \u001b[38;5;66;03m# _agg_general() returns. GH #31422\u001b[39;00m\n\u001b[0;32m   2188\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m com\u001b[38;5;241m.\u001b[39mtemp_setattr(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobserved\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m-> 2189\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_agg_general\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2192\u001b[0m \u001b[43m        \u001b[49m\u001b[43malias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madd\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnpfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2194\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_output(result, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1506\u001b[0m, in \u001b[0;36mGroupBy._agg_general\u001b[1;34m(self, numeric_only, min_count, alias, npfunc)\u001b[0m\n\u001b[0;32m   1494\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   1495\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_agg_general\u001b[39m(\n\u001b[0;32m   1496\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1501\u001b[0m     npfunc: Callable,\n\u001b[0;32m   1502\u001b[0m ):\n\u001b[0;32m   1504\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group_selection_context():\n\u001b[0;32m   1505\u001b[0m         \u001b[38;5;66;03m# try a cython aggregation if we can\u001b[39;00m\n\u001b[1;32m-> 1506\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cython_agg_general\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m            \u001b[49m\u001b[43malt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnpfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1510\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1512\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1592\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[1;34m(self, how, alt, numeric_only, min_count)\u001b[0m\n\u001b[0;32m   1588\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m   1590\u001b[0m \u001b[38;5;66;03m# TypeError -> we may have an exception in trying to aggregate\u001b[39;00m\n\u001b[0;32m   1591\u001b[0m \u001b[38;5;66;03m#  continue and exclude the block\u001b[39;00m\n\u001b[1;32m-> 1592\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouped_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_failures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1594\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_ser \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(new_mgr) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[0;32m   1595\u001b[0m     warn_dropping_nuisance_columns_deprecated(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m), how)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\base.py:199\u001b[0m, in \u001b[0;36mSingleDataManager.grouped_reduce\u001b[1;34m(self, func, ignore_failures)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;124;03mignore_failures : bool, default False\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;124;03m    Not used; for compatibility with ArrayManager/BlockManager.\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    198\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray\n\u001b[1;32m--> 199\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m index \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(res))\n\u001b[0;32m    202\u001b[0m mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_array(res, index)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1578\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21marray_func\u001b[39m(values: ArrayLike) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[0;32m   1577\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1578\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cython_operation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1579\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maggregate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_count\u001b[49m\n\u001b[0;32m   1580\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1581\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m   1582\u001b[0m         \u001b[38;5;66;03m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[0;32m   1583\u001b[0m         \u001b[38;5;66;03m# and non-applicable functions\u001b[39;00m\n\u001b[0;32m   1584\u001b[0m         \u001b[38;5;66;03m# try to python agg\u001b[39;00m\n\u001b[0;32m   1585\u001b[0m         \u001b[38;5;66;03m# TODO: shouldn't min_count matter?\u001b[39;00m\n\u001b[0;32m   1586\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:939\u001b[0m, in \u001b[0;36mBaseGrouper._cython_operation\u001b[1;34m(self, kind, values, how, axis, min_count, **kwargs)\u001b[0m\n\u001b[0;32m    937\u001b[0m ids, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_info\n\u001b[0;32m    938\u001b[0m ngroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngroups\n\u001b[1;32m--> 939\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cy_op\u001b[38;5;241m.\u001b[39mcython_operation(\n\u001b[0;32m    940\u001b[0m     values\u001b[38;5;241m=\u001b[39mvalues,\n\u001b[0;32m    941\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    942\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m    943\u001b[0m     comp_ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[0;32m    944\u001b[0m     ngroups\u001b[38;5;241m=\u001b[39mngroups,\n\u001b[0;32m    945\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    946\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:614\u001b[0m, in \u001b[0;36mWrappedCythonOp.cython_operation\u001b[1;34m(self, values, axis, min_count, comp_ids, ngroups, **kwargs)\u001b[0m\n\u001b[0;32m    610\u001b[0m is_numeric \u001b[38;5;241m=\u001b[39m is_numeric_dtype(dtype)\n\u001b[0;32m    612\u001b[0m \u001b[38;5;66;03m# can we do this operation with our cython functions\u001b[39;00m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;66;03m# if not raise NotImplementedError\u001b[39;00m\n\u001b[1;32m--> 614\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_disallow_invalid_ops\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_numeric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;66;03m# i.e. ExtensionArray\u001b[39;00m\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ea_wrap_cython_operation(\n\u001b[0;32m    619\u001b[0m         values,\n\u001b[0;32m    620\u001b[0m         min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    623\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    624\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:239\u001b[0m, in \u001b[0;36mWrappedCythonOp._disallow_invalid_ops\u001b[1;34m(self, dtype, is_numeric)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_datetime64_any_dtype(dtype):\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;66;03m# we raise NotImplemented if this is an invalid operation\u001b[39;00m\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;66;03m#  entirely, e.g. adding datetimes\u001b[39;00m\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madd\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprod\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcumsum\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcumprod\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 239\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime64 type does not support \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m operations\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_timedelta64_dtype(dtype):\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprod\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcumprod\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "\u001b[1;31mTypeError\u001b[0m: datetime64 type does not support add operations"
     ]
    }
   ],
   "source": [
    "results = list(result)\n",
    "#quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "self_comm2",
   "language": "python",
   "name": "self_comm2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
